/* eslint-disable @typescript-eslint/no-explicit-any */
import { GoogleGenerativeAI } from '@google/generative-ai';

export class LLMClient {
  private geminiClient: any;
  private temperature: number;
  private maxTokens: number;

  constructor(config: any = {}) {
    this.temperature = config.temperature || 0.7;
    this.maxTokens = config.maxTokens || 8000;

    if (!config.geminiApiKey) {
      throw new Error('GOOGLE_AI_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
    }

    const genAI = new GoogleGenerativeAI(config.geminiApiKey);
    this.geminiClient = genAI.getGenerativeModel({
      model: 'gemini-2.5-flash', // ìµœì‹  ë¬´ë£Œ ëª¨ë¸ ì‹œë„
      generationConfig: {
        temperature: this.temperature,
        maxOutputTokens: this.maxTokens,
      },
    });
    console.log('âœ… Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (gemini-2.5-flash)\n');
  }

  async generate(prompt: string): Promise<string> {
    console.log('ğŸ¤– Gemini í˜¸ì¶œ ì¤‘...');
    const result = await this.geminiClient.generateContent(prompt);
    const response = await result.response;
    return response.text();
  }

  /**
   * Markdown í˜•ì‹ìœ¼ë¡œ ì‘ë‹µì„ ë°›ì•„ ë°˜í™˜
   * JSONë³´ë‹¤ ì•ˆì •ì ì´ê³  LLMì´ ë” ì˜ ìƒì„±í•¨
   */
  async generateMarkdown(prompt: string): Promise<string> {
    const instruction =
      '\n\nì¤‘ìš”: êµ¬ì¡°í™”ëœ Markdown í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”. ëª…í™•í•œ ì œëª©(##)ê³¼ ëª©ë¡ì„ ì‚¬ìš©í•˜ì„¸ìš”.';
    const fullPrompt = prompt + instruction;
    const response = await this.generate(fullPrompt);
    return response.trim();
  }

  getProvider() {
    return 'gemini';
  }
}

export function createLLMClient(config?: any): LLMClient {
  console.log({ 'createLLMClient config': config });

  return new LLMClient({
    geminiApiKey: process.env.GOOGLE_AI_KEY,
    temperature: parseFloat(process.env.LLM_TEMPERATURE || '0.7'),
    maxTokens: parseInt(process.env.LLM_MAX_TOKENS || '8000'),
  });
}
